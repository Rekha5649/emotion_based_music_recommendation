{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR58Qh6M6FE0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ac50de2d-1b62-4a2d-d9d0-021e93bf203c"
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b1a0737-651d-4600-ad54-595e841eef39\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0b1a0737-651d-4600-ad54-595e841eef39\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving archive.zip to archive.zip\n",
            "User uploaded file \"archive.zip\" with length 63252113 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YENaXENf1jW8",
        "outputId": "cb68b7d5-7efe-48f8-b12e-5057abb617ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe359_y6nTtw",
        "outputId": "8b40eecd-7277-494f-ba48-f717f470aab8"
      },
      "source": [
        "%cd /content/drive/MyDrive/EBMRS/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/EBMRS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh9qEv6EnN2T",
        "outputId": "c83fdc80-3bc5-49e9-e058-d2353cebad74"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "archive.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAtguq7DtYfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9418d4c9-7386-4a7d-86ba-a994abab2b88"
      },
      "source": [
        "# !mv emotion1.ipynb /content/drive/MyDrive/EBMRS"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'emotion.ipynb': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2790uvwn6LNQ"
      },
      "source": [
        "# !unzip '/content/drive/MyDrive/EBMRS/archive.zip' -d '/content/drive/MyDrive/EBMRS/tt_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0EgZfhmUiLY"
      },
      "source": [
        "# labels: 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnUDYXIC7UwJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr4KLd3h7M1u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "22f17b80-752c-4758-d905-46c5d8c9da0b"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "img = image.load_img('tt_data/train/angry/Training_37417413.jpg',target_size=(48,48))\n",
        "img = np.array(img)\n",
        "plt.imshow(img)\n",
        "print(img.shape)\n",
        "\n",
        "img = np.expand_dims(img, axis=0)\n",
        "from keras.models import load_model\n",
        "print(img.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 48, 3)\n",
            "(1, 48, 48, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIQewNJg4GSo"
      },
      "source": [
        "# DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns8EVi37X_JW"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1RB75MTr3-7"
      },
      "source": [
        "batch_size = 32"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP6IM7geXYom"
      },
      "source": [
        "train_datagen1 = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range=5,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,        #zoom in the range [1-zoom_range,1+zoom_range]\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "valid_datagen1 = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2)\n",
        "\n",
        "test_datagen1  = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKIVJZf6YPYa",
        "outputId": "725d2d8d-9b30-4085-b1a1-eb0cb8d0e021"
      },
      "source": [
        "train_dataset1  = train_datagen1.flow_from_directory(directory = 'tt_data/train',\n",
        "                                                   target_size = (48,48),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   color_mode = 'grayscale',\n",
        "                                                   shuffle = True,\n",
        "                                                   batch_size = batch_size)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28709 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feOeU3-mYV6D",
        "outputId": "a8af5c9a-7bf9-4382-87df-2e2ff1bce6f9"
      },
      "source": [
        "valid_dataset1 = valid_datagen1.flow_from_directory(directory = 'tt_data/train',\n",
        "                                                  target_size = (48,48),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  color_mode = 'grayscale',\n",
        "                                                  batch_size = batch_size, \n",
        "                                                  shuffle = True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5741 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lscNDGnbZ1zY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54734f2-2885-4317-b9c4-00266c5ca668"
      },
      "source": [
        "test_dataset1 = test_datagen1.flow_from_directory(directory = 'tt_data/test',\n",
        "                                                  target_size = (48,48),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  color_mode = 'grayscale',\n",
        "                                                  batch_size = batch_size, \n",
        "                                                  shuffle = True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7178 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL3tYQPfqgXY",
        "outputId": "8bdd9ebf-1034-467a-a2fa-a85aea90a45a"
      },
      "source": [
        "train_img = train_dataset1.next()[0]\n",
        "train_lables = train_dataset1.next()[1]\n",
        "valid_img = valid_dataset1.next()[0]\n",
        "valid_lables = valid_dataset1.next()[1]\n",
        "\n",
        "print(f'shape of the train dataset: {train_img.shape}')\n",
        "print(f'shape of the train labels: {train_lables.shape}')\n",
        "print(f'shape of the validation dataset: {train_img.shape}')\n",
        "print(f'shape of the validation labels: {train_lables.shape}')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the train dataset: (32, 48, 48, 1)\n",
            "shape of the train labels: (32, 7)\n",
            "shape of the validation dataset: (32, 48, 48, 1)\n",
            "shape of the validation labels: (32, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AngOdWowuNWW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMy2wqnJJJEq"
      },
      "source": [
        "# Convolution neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzN3IBwXCpEW"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvqT1YvksmTe"
      },
      "source": [
        "def build_model():  \n",
        "  model = keras.Sequential([\n",
        "                            \n",
        "    #block-1                      \n",
        "    Conv2D(filters=32, kernel_size=(3,3), kernel_initializer='he_normal', activation='relu', input_shape=(48,48,1)),\n",
        "    Conv2D(filters=64, kernel_size=(3,3), kernel_initializer='he_normal', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    #block-2\n",
        "    Conv2D(filters=128, kernel_size=(3,3), kernel_initializer='he_normal', activation='relu'),\n",
        "    Conv2D(filters=256, kernel_size=(3,3), kernel_initializer='he_normal', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(7, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xVR0r0vs5_1"
      },
      "source": [
        "cnn_model = build_model()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWOohJ7ItHQa",
        "outputId": "b2736539-9c3b-45dc-f576-29c8e7b441c3"
      },
      "source": [
        "history = cnn_model.fit(\n",
        "    train_dataset1,\n",
        "    validation_data=valid_dataset1,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=len(train_dataset1),\n",
        "    validation_steps=len(valid_dataset1)\n",
        ")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 58s 63ms/step - loss: 1.9198 - accuracy: 0.2346 - val_loss: 1.8961 - val_accuracy: 0.2048\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 56s 62ms/step - loss: 1.7315 - accuracy: 0.2985 - val_loss: 1.9242 - val_accuracy: 0.2782\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.5895 - accuracy: 0.3745 - val_loss: 1.4374 - val_accuracy: 0.4466\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 57s 63ms/step - loss: 1.4535 - accuracy: 0.4421 - val_loss: 1.3161 - val_accuracy: 0.4963\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 56s 62ms/step - loss: 1.3616 - accuracy: 0.4745 - val_loss: 1.2742 - val_accuracy: 0.4990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji0cZyOVumUZ",
        "outputId": "23fa8624-e546-4f57-c427-33cf8594e73a"
      },
      "source": [
        "history1 = cnn_model.fit(\n",
        "    train_dataset1,\n",
        "    validation_data=valid_dataset1,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_dataset1),\n",
        "    validation_steps=len(valid_dataset1)\n",
        ")\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "898/898 [==============================] - 56s 63ms/step - loss: 1.2879 - accuracy: 0.5087 - val_loss: 1.2397 - val_accuracy: 0.5271\n",
            "Epoch 2/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.2449 - accuracy: 0.5269 - val_loss: 1.2660 - val_accuracy: 0.5213\n",
            "Epoch 3/50\n",
            "898/898 [==============================] - 54s 61ms/step - loss: 1.2265 - accuracy: 0.5350 - val_loss: 1.2289 - val_accuracy: 0.5361\n",
            "Epoch 4/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.1876 - accuracy: 0.5479 - val_loss: 1.0989 - val_accuracy: 0.5865\n",
            "Epoch 5/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.1791 - accuracy: 0.5524 - val_loss: 1.0815 - val_accuracy: 0.5908\n",
            "Epoch 6/50\n",
            "898/898 [==============================] - 55s 62ms/step - loss: 1.1573 - accuracy: 0.5616 - val_loss: 1.0509 - val_accuracy: 0.5968\n",
            "Epoch 7/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.1484 - accuracy: 0.5640 - val_loss: 1.0919 - val_accuracy: 0.5842\n",
            "Epoch 8/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.1315 - accuracy: 0.5732 - val_loss: 1.0519 - val_accuracy: 0.6157\n",
            "Epoch 9/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.1129 - accuracy: 0.5817 - val_loss: 1.0284 - val_accuracy: 0.6182\n",
            "Epoch 10/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.1020 - accuracy: 0.5848 - val_loss: 0.9962 - val_accuracy: 0.6196\n",
            "Epoch 11/50\n",
            "898/898 [==============================] - 54s 61ms/step - loss: 1.0976 - accuracy: 0.5825 - val_loss: 1.0102 - val_accuracy: 0.6182\n",
            "Epoch 12/50\n",
            "898/898 [==============================] - 56s 62ms/step - loss: 1.0784 - accuracy: 0.5940 - val_loss: 1.0257 - val_accuracy: 0.6095\n",
            "Epoch 13/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.0710 - accuracy: 0.5983 - val_loss: 0.9756 - val_accuracy: 0.6283\n",
            "Epoch 14/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.0660 - accuracy: 0.6002 - val_loss: 0.9859 - val_accuracy: 0.6274\n",
            "Epoch 15/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.0533 - accuracy: 0.6038 - val_loss: 1.0099 - val_accuracy: 0.6250\n",
            "Epoch 16/50\n",
            "898/898 [==============================] - 59s 65ms/step - loss: 1.0403 - accuracy: 0.6076 - val_loss: 0.9514 - val_accuracy: 0.6427\n",
            "Epoch 17/50\n",
            "898/898 [==============================] - 55s 62ms/step - loss: 1.0393 - accuracy: 0.6087 - val_loss: 0.9887 - val_accuracy: 0.6347\n",
            "Epoch 18/50\n",
            "898/898 [==============================] - 56s 62ms/step - loss: 1.0281 - accuracy: 0.6155 - val_loss: 0.9536 - val_accuracy: 0.6438\n",
            "Epoch 19/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 1.0173 - accuracy: 0.6202 - val_loss: 0.9762 - val_accuracy: 0.6335\n",
            "Epoch 20/50\n",
            "898/898 [==============================] - 56s 62ms/step - loss: 1.0215 - accuracy: 0.6136 - val_loss: 0.9071 - val_accuracy: 0.6569\n",
            "Epoch 21/50\n",
            "898/898 [==============================] - 56s 62ms/step - loss: 1.0113 - accuracy: 0.6195 - val_loss: 0.9087 - val_accuracy: 0.6541\n",
            "Epoch 22/50\n",
            "898/898 [==============================] - 54s 61ms/step - loss: 0.9956 - accuracy: 0.6220 - val_loss: 0.9361 - val_accuracy: 0.6591\n",
            "Epoch 23/50\n",
            "898/898 [==============================] - 55s 62ms/step - loss: 0.9974 - accuracy: 0.6234 - val_loss: 0.9495 - val_accuracy: 0.6461\n",
            "Epoch 24/50\n",
            "898/898 [==============================] - 54s 60ms/step - loss: 0.9950 - accuracy: 0.6249 - val_loss: 0.9447 - val_accuracy: 0.6401\n",
            "Epoch 25/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9869 - accuracy: 0.6287 - val_loss: 0.9461 - val_accuracy: 0.6440\n",
            "Epoch 26/50\n",
            "898/898 [==============================] - 54s 61ms/step - loss: 0.9819 - accuracy: 0.6316 - val_loss: 0.8839 - val_accuracy: 0.6776\n",
            "Epoch 27/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9676 - accuracy: 0.6374 - val_loss: 0.8937 - val_accuracy: 0.6670\n",
            "Epoch 28/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9713 - accuracy: 0.6366 - val_loss: 0.8633 - val_accuracy: 0.6783\n",
            "Epoch 29/50\n",
            "898/898 [==============================] - 55s 62ms/step - loss: 0.9634 - accuracy: 0.6405 - val_loss: 0.8554 - val_accuracy: 0.6821\n",
            "Epoch 30/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9559 - accuracy: 0.6412 - val_loss: 0.8571 - val_accuracy: 0.6832\n",
            "Epoch 31/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9541 - accuracy: 0.6414 - val_loss: 0.8588 - val_accuracy: 0.6776\n",
            "Epoch 32/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9456 - accuracy: 0.6432 - val_loss: 0.8423 - val_accuracy: 0.6886\n",
            "Epoch 33/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9440 - accuracy: 0.6449 - val_loss: 0.8859 - val_accuracy: 0.6692\n",
            "Epoch 34/50\n",
            "898/898 [==============================] - 55s 62ms/step - loss: 0.9412 - accuracy: 0.6473 - val_loss: 0.8630 - val_accuracy: 0.6750\n",
            "Epoch 35/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9368 - accuracy: 0.6478 - val_loss: 0.8409 - val_accuracy: 0.6868\n",
            "Epoch 36/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9318 - accuracy: 0.6511 - val_loss: 0.8706 - val_accuracy: 0.6710\n",
            "Epoch 37/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9321 - accuracy: 0.6511 - val_loss: 0.8761 - val_accuracy: 0.6776\n",
            "Epoch 38/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9227 - accuracy: 0.6558 - val_loss: 0.8131 - val_accuracy: 0.6941\n",
            "Epoch 39/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9182 - accuracy: 0.6577 - val_loss: 0.8191 - val_accuracy: 0.6953\n",
            "Epoch 40/50\n",
            "898/898 [==============================] - 56s 62ms/step - loss: 0.9060 - accuracy: 0.6599 - val_loss: 0.8303 - val_accuracy: 0.6889\n",
            "Epoch 41/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9037 - accuracy: 0.6611 - val_loss: 0.7941 - val_accuracy: 0.7053\n",
            "Epoch 42/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.9100 - accuracy: 0.6622 - val_loss: 0.8363 - val_accuracy: 0.6868\n",
            "Epoch 43/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.8983 - accuracy: 0.6664 - val_loss: 0.8015 - val_accuracy: 0.7020\n",
            "Epoch 44/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.8974 - accuracy: 0.6631 - val_loss: 0.7951 - val_accuracy: 0.7063\n",
            "Epoch 45/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.8878 - accuracy: 0.6673 - val_loss: 0.8423 - val_accuracy: 0.6889\n",
            "Epoch 46/50\n",
            "898/898 [==============================] - 55s 62ms/step - loss: 0.8910 - accuracy: 0.6668 - val_loss: 0.8030 - val_accuracy: 0.7041\n",
            "Epoch 47/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.8835 - accuracy: 0.6708 - val_loss: 0.7878 - val_accuracy: 0.7131\n",
            "Epoch 48/50\n",
            "898/898 [==============================] - 55s 61ms/step - loss: 0.8760 - accuracy: 0.6710 - val_loss: 0.7915 - val_accuracy: 0.7049\n",
            "Epoch 49/50\n",
            "898/898 [==============================] - 54s 60ms/step - loss: 0.8822 - accuracy: 0.6710 - val_loss: 0.8496 - val_accuracy: 0.6872\n",
            "Epoch 50/50\n",
            "898/898 [==============================] - 54s 60ms/step - loss: 0.8746 - accuracy: 0.6719 - val_loss: 0.7763 - val_accuracy: 0.7096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIRgmdRw5bxU",
        "outputId": "038044eb-5795-4c69-f6ee-5c769af1fd69"
      },
      "source": [
        "result = new_model.evaluate(\n",
        "    test_dataset1,\n",
        "    batch_size = batch_size,\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 8s 36ms/step - loss: 0.9788 - accuracy: 0.6427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJyfuB0nT6kW"
      },
      "source": [
        "# !rm -rf emotio_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJmdeWuH9OtR"
      },
      "source": [
        "# {'conv_1_filter': 64, 'conv_1_kernel': 3, 'conv_2_filter': 64, 'conv_2_kernel': 3, 'conv_3_filter': 64, 'conv_3_kernel': 3, 'conv_4_filter': 64, 'conv_4_kernel': 5, 'dense_1_units': 128, 'learning_rate': 0.001, 'tuner/epochs': 5, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZaSCH3VpALE"
      },
      "source": [
        "cnn_model.save('cnn_model.h5')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL6Q0AySRrAg"
      },
      "source": [
        "new_model = keras.models.load_model('cnn_model.h5')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3L0O3brQ2J_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxQg19DMIjU6"
      },
      "source": [
        "# VGG tranfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XUCsjW40pR9"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  #  validation_split = 0.2,\n",
        "                                   rotation_range=5,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,        #zoom in the range [1-zoom_range,1+zoom_range]\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPUhjnbx1RXQ",
        "outputId": "fb25bb4a-69f7-461a-b6a0-a4929a38cf07"
      },
      "source": [
        "train_dataset  = train_datagen.flow_from_directory(directory = 'tt_data/train',\n",
        "                                                   target_size = (224,224),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   shuffle = True,\n",
        "                                                   batch_size = 64)\n",
        "\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(directory = 'tt_data/train',\n",
        "                                                  target_size = (224,224),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  batch_size = 64, \n",
        "                                                  shuffle = True)\n",
        "\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(directory = 'tt_data/test',\n",
        "                                                  target_size = (224,224),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 64, \n",
        "                                                  shuffle = True)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 5741 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuvNzbb211nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03c0328-a101-4308-84f3-d5353263a905"
      },
      "source": [
        "r = model.fit_generator(\n",
        "  train_dataset,\n",
        "  validation_data=valid_dataset,\n",
        "  epochs=5,\n",
        "  steps_per_epoch=len(train_dataset),\n",
        "  validation_steps=len(valid_dataset)\n",
        ")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "449/449 [==============================] - 416s 836ms/step - loss: 1.8788 - accuracy: 0.2894 - val_loss: 1.5191 - val_accuracy: 0.4137\n",
            "Epoch 2/5\n",
            "449/449 [==============================] - 360s 801ms/step - loss: 1.7027 - accuracy: 0.3566 - val_loss: 1.5366 - val_accuracy: 0.4304\n",
            "Epoch 3/5\n",
            "449/449 [==============================] - 363s 808ms/step - loss: 1.6580 - accuracy: 0.3788 - val_loss: 1.6229 - val_accuracy: 0.4376\n",
            "Epoch 4/5\n",
            "449/449 [==============================] - 363s 808ms/step - loss: 1.6569 - accuracy: 0.3820 - val_loss: 1.5949 - val_accuracy: 0.4161\n",
            "Epoch 5/5\n",
            "449/449 [==============================] - 363s 808ms/step - loss: 1.6143 - accuracy: 0.3914 - val_loss: 1.6339 - val_accuracy: 0.4198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QCOWWViydUb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auM6r_3gyd1c"
      },
      "source": [
        "# **ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f1XWEjlybIH"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGmLNC4_ycfm",
        "outputId": "b3adfb4f-0bd1-4443-f84e-8dff27c96f42"
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = 'tt_data/train'\n",
        "valid_path = 'tt_data/test'\n",
        "\n",
        "# add preprocessing layer to the front of VGG\n",
        "rn = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "# don't train existing weights\n",
        "for layer in rn.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "\n",
        "  \n",
        "  # useful for getting number of classes\n",
        "folders = glob('tt_data/train/*')\n",
        "  \n",
        "\n",
        "# our layers - you can add more if you want\n",
        "x = Flatten()(rn.output)\n",
        "\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "modelr = Model(inputs=rn.input, outputs=prediction)\n",
        "\n",
        "# view the structure of the model\n",
        "modelr.summary()\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 7)            702471      flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 24,290,183\n",
            "Trainable params: 702,471\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_xHd15vy4Tq"
      },
      "source": [
        "modelr.compile(loss='categorical_crossentropy', \n",
        "                  optimizer='adam', \n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIRl6CGyALSL"
      },
      "source": [
        "from keras.optimizers import RMSprop,SGD,Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint('cnn_model.h5',\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True\n",
        "                          )\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)\n",
        "\n",
        "callbacks = [earlystop,checkpoint,reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdJikUpQy_Bh",
        "outputId": "b4f100a7-a3d5-48b5-b201-e76a05d9412c"
      },
      "source": [
        "rh = modelr.fit_generator(\n",
        "  train_dataset,\n",
        "  validation_data=valid_dataset,\n",
        "  epochs=5,\n",
        "  steps_per_epoch=len(train_dataset),\n",
        "  validation_steps=len(valid_dataset)\n",
        ")\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "449/449 [==============================] - 352s 776ms/step - loss: 3.2301 - accuracy: 0.1936 - val_loss: 2.0477 - val_accuracy: 0.1805\n",
            "Epoch 2/5\n",
            "449/449 [==============================] - 346s 770ms/step - loss: 2.1144 - accuracy: 0.2162 - val_loss: 2.2980 - val_accuracy: 0.1926\n",
            "Epoch 3/5\n",
            "449/449 [==============================] - 345s 768ms/step - loss: 2.1960 - accuracy: 0.2221 - val_loss: 2.0994 - val_accuracy: 0.1930\n",
            "Epoch 4/5\n",
            "449/449 [==============================] - 345s 768ms/step - loss: 2.1445 - accuracy: 0.2340 - val_loss: 2.3079 - val_accuracy: 0.2940\n",
            "Epoch 5/5\n",
            "449/449 [==============================] - 345s 768ms/step - loss: 2.2364 - accuracy: 0.2259 - val_loss: 2.7573 - val_accuracy: 0.2620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZB74OAZBlLq"
      },
      "source": [
        "# **CNN other**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izLQvwkDBkmi",
        "outputId": "c89c7ed3-eb8d-4e20-eac3-bb91f605ed11"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Block-1\n",
        "\n",
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,1)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,1)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block-2 \n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block-3\n",
        "\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block-4 \n",
        "\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block-5\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Block-6\n",
        "\n",
        "model.add(Dense(64,kernel_initializer='he_normal'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Block-7\n",
        "\n",
        "model.add(Dense(7,kernel_initializer='he_normal'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 48, 48, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 48, 48, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 48, 48, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 12, 12, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 6, 6, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                147520    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 455       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 1,328,167\n",
            "Trainable params: 1,325,991\n",
            "Non-trainable params: 2,176\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en22iN96BkHC"
      },
      "source": [
        "from keras.optimizers import RMSprop,SGD,Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint('Emotion_little_vgg.h5',\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True\n",
        "                          )\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)\n",
        "\n",
        "callbacks = [earlystop,checkpoint,reduce_lr]\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKwvRWJLCIZ0",
        "outputId": "4b9f886d-ca3e-4430-ccba-0a2f69bfcd7d"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_train_samples = 28709\n",
        "nb_validation_samples = 5741\n",
        "epochs=25\n",
        "\n",
        "history=model.fit(\n",
        "                train_dataset1,\n",
        "                steps_per_epoch=nb_train_samples//32,\n",
        "                epochs=epochs,\n",
        "                callbacks=callbacks,\n",
        "                validation_data=valid_dataset1,\n",
        "                validation_steps=nb_validation_samples//32)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "897/897 [==============================] - 57s 62ms/step - loss: 2.4341 - accuracy: 0.1909 - val_loss: 1.8152 - val_accuracy: 0.2750\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.81515, saving model to Emotion_little_vgg.h5\n",
            "Epoch 2/25\n",
            "897/897 [==============================] - 55s 62ms/step - loss: 1.7813 - accuracy: 0.2763 - val_loss: 1.5193 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.81515 to 1.51928, saving model to Emotion_little_vgg.h5\n",
            "Epoch 3/25\n",
            "897/897 [==============================] - 55s 61ms/step - loss: 1.6066 - accuracy: 0.3709 - val_loss: 1.3527 - val_accuracy: 0.4811\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.51928 to 1.35273, saving model to Emotion_little_vgg.h5\n",
            "Epoch 4/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.4554 - accuracy: 0.4399 - val_loss: 1.2930 - val_accuracy: 0.5017\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.35273 to 1.29304, saving model to Emotion_little_vgg.h5\n",
            "Epoch 5/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.3801 - accuracy: 0.4731 - val_loss: 1.2123 - val_accuracy: 0.5246\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.29304 to 1.21228, saving model to Emotion_little_vgg.h5\n",
            "Epoch 6/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.3168 - accuracy: 0.5063 - val_loss: 1.1734 - val_accuracy: 0.5522\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.21228 to 1.17343, saving model to Emotion_little_vgg.h5\n",
            "Epoch 7/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.2983 - accuracy: 0.5161 - val_loss: 1.1492 - val_accuracy: 0.5681\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.17343 to 1.14919, saving model to Emotion_little_vgg.h5\n",
            "Epoch 8/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.2571 - accuracy: 0.5304 - val_loss: 1.1527 - val_accuracy: 0.5595\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.14919\n",
            "Epoch 9/25\n",
            "897/897 [==============================] - 55s 62ms/step - loss: 1.2203 - accuracy: 0.5541 - val_loss: 1.1264 - val_accuracy: 0.5726\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.14919 to 1.12635, saving model to Emotion_little_vgg.h5\n",
            "Epoch 10/25\n",
            "897/897 [==============================] - 55s 62ms/step - loss: 1.2094 - accuracy: 0.5537 - val_loss: 1.0802 - val_accuracy: 0.5990\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.12635 to 1.08021, saving model to Emotion_little_vgg.h5\n",
            "Epoch 11/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.1822 - accuracy: 0.5640 - val_loss: 1.0629 - val_accuracy: 0.5924\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.08021 to 1.06292, saving model to Emotion_little_vgg.h5\n",
            "Epoch 12/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.1614 - accuracy: 0.5708 - val_loss: 1.0211 - val_accuracy: 0.6147\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.06292 to 1.02109, saving model to Emotion_little_vgg.h5\n",
            "Epoch 13/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.1505 - accuracy: 0.5759 - val_loss: 1.0012 - val_accuracy: 0.6285\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.02109 to 1.00125, saving model to Emotion_little_vgg.h5\n",
            "Epoch 14/25\n",
            "897/897 [==============================] - 55s 62ms/step - loss: 1.1408 - accuracy: 0.5816 - val_loss: 0.9686 - val_accuracy: 0.6444\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.00125 to 0.96857, saving model to Emotion_little_vgg.h5\n",
            "Epoch 15/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.1218 - accuracy: 0.5895 - val_loss: 0.9994 - val_accuracy: 0.6229\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.96857\n",
            "Epoch 16/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.1098 - accuracy: 0.5965 - val_loss: 1.0001 - val_accuracy: 0.6271\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.96857\n",
            "Epoch 17/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.0960 - accuracy: 0.6020 - val_loss: 0.9635 - val_accuracy: 0.6383\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.96857 to 0.96352, saving model to Emotion_little_vgg.h5\n",
            "Epoch 18/25\n",
            "897/897 [==============================] - 56s 63ms/step - loss: 1.0950 - accuracy: 0.6047 - val_loss: 0.9423 - val_accuracy: 0.6512\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.96352 to 0.94228, saving model to Emotion_little_vgg.h5\n",
            "Epoch 19/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.0805 - accuracy: 0.6014 - val_loss: 0.9190 - val_accuracy: 0.6629\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.94228 to 0.91902, saving model to Emotion_little_vgg.h5\n",
            "Epoch 20/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.0591 - accuracy: 0.6154 - val_loss: 0.9244 - val_accuracy: 0.6562\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.91902\n",
            "Epoch 21/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.0765 - accuracy: 0.6047 - val_loss: 0.9188 - val_accuracy: 0.6576\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.91902 to 0.91877, saving model to Emotion_little_vgg.h5\n",
            "Epoch 22/25\n",
            "897/897 [==============================] - 55s 62ms/step - loss: 1.0617 - accuracy: 0.6116 - val_loss: 0.8847 - val_accuracy: 0.6730\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.91877 to 0.88474, saving model to Emotion_little_vgg.h5\n",
            "Epoch 23/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.0348 - accuracy: 0.6239 - val_loss: 0.8849 - val_accuracy: 0.6749\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.88474\n",
            "Epoch 24/25\n",
            "897/897 [==============================] - 56s 63ms/step - loss: 1.0371 - accuracy: 0.6222 - val_loss: 0.8916 - val_accuracy: 0.6718\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.88474\n",
            "Epoch 25/25\n",
            "897/897 [==============================] - 56s 62ms/step - loss: 1.0365 - accuracy: 0.6227 - val_loss: 0.8948 - val_accuracy: 0.6716\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.88474\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 00025: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhL1ymDFIyBo",
        "outputId": "e366a405-1745-4845-f6ec-d96e12ad2bf0"
      },
      "source": [
        "result = model.evaluate(\n",
        "    test_dataset1,\n",
        "    batch_size = batch_size,\n",
        ")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 8s 37ms/step - loss: 0.9712 - accuracy: 0.6408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gONpRSjNRFED"
      },
      "source": [
        "# **SAVE** **MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT71Mgjj2XCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4a48cf81-31ea-4289-dda3-ebc5a5fab441"
      },
      "source": [
        "# loss\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss1')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8imMb-HWqodT",
        "outputId": "6bf293e0-cf00-4a67-e3e2-28c9d67a843d"
      },
      "source": [
        "# accuracies\n",
        "plt.plot(history.history['accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc1')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rieM8andqlVt"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "\n",
        "model.save('facefeatures_new_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}